<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Skill Learning | Daniel C.H Tan</title> <meta name="author" content="Daniel C.H Tan"/> <meta name="description" content="Thoughts on learning general and re-usable skills for continuous-control tasks in robotics"/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://daniel-ch-tan.github.io/blog/2022/skill-learning/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <d-front-matter> <script async type="text/json">{
      "title": "Skill Learning",
      "description": "Thoughts on learning general and re-usable skills for continuous-control tasks in robotics",
      "published": "January 13, 2022",
      "authors": [
        {
          "author": "Daniel C.H Tan",
          "authorURL": "daniel-ch-tan.github.io",
          "affiliations": [
            {
              "name": "UCL CS, A*STAR",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Daniel </span>C.H Tan</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Skill Learning</h1> <p>Thoughts on learning general and re-usable skills for continuous-control tasks in robotics</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#introduction">Introduction</a></div> <div><a href="#related-work">Related Work</a></div> <div><a href="#learning-skills">Learning Skills</a></div> <div><a href="#using-skills">Using Skills</a></div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>As humans, we have learned certain patterns of whole-body actuation as high-level “skills” (walking, running, jumping, etc.) In planning our bodily actions, we do not consciously control each and every actuator (muscle) in our body. Rather,we largely constrain ourselves to these general and re-usable patterns, adapting and composing them on the fly to fit the situation. Why not do the same for robots?</p> <p>In this blog post, I will describe the motivations and approaches for skill learning in control problems, i.e. to <strong>learn</strong> and <strong>discover</strong> a <strong>diverse</strong> and <strong>high-quality</strong> set of <strong>action primitives</strong> that <strong>transfer well</strong> to downstream tasks.</p> <h2 id="motivation">Motivation</h2> <h3 id="the-cereal-making-robot">The Cereal-Making Robot</h3> <p>An average ten-year-old could probably walk into the kitchen and make themselves a bowl of cereal unsupervised. Yet the same capability remains out of reach of modern robots. (Or at the least, it has yet to be demonstrated!) Why is that? (Example credit: Chelsea Finn, <a href="https://thegradientpub.substack.com/p/chelsea-finn-on-meta-learning-and#details" target="_blank" rel="noopener noreferrer">podcast episode</a> hosted by <a href="https://thegradientpub.substack.com/s/podcast" target="_blank" rel="noopener noreferrer">The Gradient</a>).</p> <div class="row mt-3" style="position: relative"> <div class="col-sm mt-3 mt-md-0" style="width: 50%"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/skill_learning/cereal-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/skill_learning/cereal-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/skill_learning/cereal-1400.webp"></source> <img src="/assets/img/skill_learning/cereal.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Making cereal is so easy, even kids can do it! </div> <p>More generally, we would like to develop control frameworks that enable robots to accomplish <strong>complex tasks</strong> in the <strong>real world</strong>. </p> <h3 id="skills-as-building-blocks">Skills as Building Blocks</h3> <p>One method of enabling complex task-oriented behaviour, is to adopt an incremental approach and try to learn to solve simpler subproblems first, then compose those solutions into a full solution. As programmers, this sounds inherently appealing. Going back to the cereal analogy, we might come up with a list of lower-level skills that need to be learned first, such as <strong>finding</strong> the necessary ingredients, <strong>picking</strong> up the cereal box, <strong>pouring</strong> the milk into a bowl, and <strong>carrying</strong> it out of the kitchen while maintaining good <strong>balance</strong>.</p> <p>If we had access to high-quality action primitives that were able to solve each of these subproblems, the overall problem reduces to a simple task of finding the right skills and sequencing them in the right order. Conversely, needing to learn to solve all of these subproblems from scratch makes the overall problem exponentially more difficult.</p> <p>The core problem of skill learning is therefore to discover and learn a diverse set of high-quality action primitives that transfer well to downstream tasks.</p> <h3 id="skills-for-dexterity">Skills for Dexterity</h3> <p>It has been said that dexterity is the “last open frontier in robotics”.</p> <p>One reason for this is that learning-based approaches struggle is the difficulty of exploration in high-dimensional control space. For a humanoid morphology, even maintaining balance is already a rather challenging task, let alone learning to move in an agile, safe, and efficient way or exercise fine motor skills in handling everyday objects.</p> <h2 id="related-work">Related work</h2> <h3 id="representation-learning">Representation Learning</h3> <p>Skill learning can be thought of as representation learning. However, while most representation learning methods aim to construct informative representations of the observations space, we are instead focusing on the action space. The space of all valid action primitives scales as \(\dim(A^T)\); yet the space of useful action primitives could be hypothesised to be restricted to a low-dimensional manifold within this combinatorially large space. Reducing the dimension of the action space has obvious benefits for improving interpretability as well as the efficiency of exploration.</p> <h3 id="options-theory">Options Theory</h3> <p>One useful mathematical formulation for skill learning is the options framework introduced in <d-cite key="sutton1999options"></d-cite>. For a given Markov Decision Process (MDP), options are auxilliary policies that conditionally execute upon entering certain states and run until their termination condition is met.</p> <h3 id="latent-variable-policies">Latent-Variable Policies</h3> <p>In practice, it has been popular <d-cite key="sharma2019dynamics"></d-cite> <d-cite key="Peng_2021"></d-cite> to implement skill learning using a latent-conditioned policy. Each instantiation of the latent variable corresponds to a single option, and the choice of distribution over the latents induces a family of options. Assuming sufficient regularity of the latent space, the latent-variable representations can be interpolated to sample novel skills.</p> <h3 id="planning-with-subgoals">Planning with subgoals</h3> <p>A similar line of reasoning is employed in <strong>subgoal</strong>-conditioned learning and planning; however, while subgoals are akin to static milestones that need to be achieved in order to reach the main goal, skills are akin to the known routes that take us safely and quickly between subgoals.</p> <h2 id="learning-skills">Learning Skills</h2> <p>Learning a skill refers to learning how to execute the skill, given that we already know what it is. Depending on choice of representation, this may be very easy; for example, if we have a skill represented as a state-action trajectory, then simple behaviour cloning would enable the skill to be learned. For the task of simulated locomotion, ASE <d-cite key="peng2022ase"></d-cite> and its predecessors used motion-capture data from known quadrupedal and bipedal experts (i.e. animals and humans).</p> <p>For a given control task and action space, domain knowledge may also give us clues about how to design families of high-quality skills. For example, in legged locomotion, classical control methods have done well by using gait-parameterized actuation as a family of skills. Similarly, generalized hybrid-zero dynamics has been an effective heuristic for designing skills for bipedal locomotion.</p> <p>However, in practice, such data and domain knowledge may not be readily available, which leads us to…</p> <h2 id="discovering-skills">Discovering Skills</h2> <p>Instead of relying on prior knowledge, we can aim to discover skills simply from pure exploration. However, in the absence of extrinsic inductive biases, skill discovery requires intrinsic priors on high-quality skills, e.g diversity and consistency of the skill set <d-cite key="sharma2019dynamics"></d-cite>. By optimizing these intrinsic metrics, we hope that skills emerge autonomously from the learning process.</p> <p>Compared to the previous approaches, there is no guarantee of quality of individual skills in the learned set. However, by maximizing diversity, we can hope that the learned skill set contains sufficient high-quality skills that transfer well to downstream tasks.</p> <h2 id="transferring-skills-to-tasks">Transferring Skills to Tasks</h2> <p>Okay, so suppose that we have a collection of high-quality skills. How do we use them in a task-oriented way?</p> <h3 id="hierarchical-learning">Hierarchical Learning</h3> <p>A suitable collection of skills can be directly used as a low-level controller. A high-level planner can then use the skill space as its action space, selecting and sequencing options to solve specific tasks.</p> <p>Doing this has several benefits. First and foremost, the high-level policy does not need to learn skills, but can simply make use of them in a zero-shot manner. Furthermore, exploration in a highly informative, low-dimensional latent space is likely to be much easier than exploration in a high-dimensional, noisy space, greatly improving sample efficiency on downstream tasks.</p> <p>To understand this, consider that simple exploration strategies in the skill space can translate to highly structured and efficient exploration in the action space. </p> <h3 id="teacher-student-learning">Teacher-Student Learning</h3> <p>Another perspective is to simply treat the learned skills as ‘teachers’ that generate off-policy state-action-reward histories, which are made available to student policies. This could be used by off-policy RL algorithms or even by imitation learning methods.</p> <p>Compared to the hierarchical approach, this has the benefit of fewer architectural constraints on the final policy. In turn, it likely trades off some of the gains in sample efficiency from directly re-using learned skills as action primitives.</p> <h2 id="conclusion">Conclusion</h2> <p>In this blog post, I discussed the motivating factors and benefits/disadvantages of the skills framework vis-a-vis reinforcement learning. I also reviewed some of the current literature in this field.</p> <p>In the next blog post, I’ll talk more about my current progress in applying a skills-based framework to robotic control tasks.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Daniel C.H Tan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <d-bibliography src="/assets/bibliography/2022-01-13-motor-skill-url.bib"></d-bibliography> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>